import { GoogleGenAI, Modality, Type } from "@google/genai";
import { ReadingMode, VoiceEmotion, AdvancedVoiceSettings } from "../types";
import { VIETNAMESE_ABBREVIATIONS } from "../constants";

const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

/**
 * Exponential backoff v·ªõi jitter ƒë·ªÉ tr√°nh thundering herd
 */
const exponentialBackoff = async (retryCount: number, baseDelay: number = 1000): Promise<void> => {
  const exponentialDelay = baseDelay * Math.pow(2, retryCount);
  const jitter = Math.random() * 1000; // Random 0-1000ms ƒë·ªÉ tr√°nh synchronized retries
  const totalDelay = Math.min(exponentialDelay + jitter, 30000); // Max 30 seconds
  await delay(totalDelay);
};

/**
 * Wrapper v·ªõi timeout cho API calls
 */
const withTimeout = <T>(promise: Promise<T>, timeoutMs: number = 30000): Promise<T> => {
  return Promise.race([
    promise,
    new Promise<T>((_, reject) => 
      setTimeout(() => reject(new Error('Request timeout after ' + timeoutMs + 'ms')), timeoutMs)
    )
  ]);
};

/**
 * Ki·ªÉm tra API Key c√≥ th·ª±c s·ª± ho·∫°t ƒë·ªông hay kh√¥ng b·∫±ng m·ªôt request t·ªëi gi·∫£n
 */
export const testApiKey = async (apiKey: string): Promise<{ valid: boolean, message: string }> => {
  try {
    const ai = new GoogleGenAI({ apiKey });
    // Th·ª≠ g·ªçi m·ªôt l·ªánh generateContent si√™u ng·∫Øn ƒë·ªÉ check key
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: "Ping",
      config: { maxOutputTokens: 1 }
    });
    if (response) return { valid: true, message: "API Key ho·∫°t ƒë·ªông t·ªët." };
    return { valid: false, message: "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ AI." };
  } catch (error: any) {
    const info = handleAiError(error);
    return { valid: false, message: info.message };
  }
};

/**
 * X·ª≠ l√Ω l·ªói Gemini API chi ti·∫øt v·ªõi Retry-After support
 */
export const handleAiError = (error: any): { 
  message: string, 
  isRateLimit: boolean, 
  shouldWait: boolean,
  retryAfter?: number 
} => {
  const rawMessage = error?.message ? String(error.message) : String(error);
  const lowerMessage = rawMessage.toLowerCase();
  
  const isRateLimit = lowerMessage.includes("429") || 
                     lowerMessage.includes("resource exhausted") || 
                     lowerMessage.includes("quota") ||
                     lowerMessage.includes("rate limit");
  const isInvalidKey = lowerMessage.includes("400") || 
                      lowerMessage.includes("401") || 
                      lowerMessage.includes("403") || 
                      lowerMessage.includes("api key") || 
                      lowerMessage.includes("invalid argument") || 
                      lowerMessage.includes("not found");
  const isSafetyBlock = lowerMessage.includes("safety") || lowerMessage.includes("blocked");
  const isTimeout = lowerMessage.includes("timeout");

  // Parse Retry-After t·ª´ response headers n·∫øu c√≥
  let retryAfter: number | undefined;
  if (error?.response?.headers?.['retry-after']) {
    retryAfter = parseInt(error.response.headers['retry-after'], 10) * 1000; // Convert to ms
  } else if (isRateLimit) {
    retryAfter = 60000; // Default 60 seconds cho rate limit
  }

  if (isRateLimit) {
    return { 
      message: "‚ùå H·∫øt h·∫°n m·ª©c (429). Vui l√≤ng th·ª≠ l·∫°i sau.", 
      isRateLimit: true, 
      shouldWait: true,
      retryAfter: retryAfter || 60000
    };
  }
  if (isInvalidKey) {
    return { 
      message: "üö´ Key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ b·ªã v√¥ hi·ªáu h√≥a.", 
      isRateLimit: false, 
      shouldWait: false 
    };
  }
  if (isSafetyBlock) {
    return { 
      message: "üõ°Ô∏è N·ªôi dung b·ªã ch·∫∑n do ch√≠nh s√°ch an to√†n.", 
      isRateLimit: false, 
      shouldWait: false 
    };
  }
  if (isTimeout) {
    return { 
      message: "‚è±Ô∏è Request timeout. Vui l√≤ng th·ª≠ l·∫°i.", 
      isRateLimit: false, 
      shouldWait: true,
      retryAfter: 5000
    };
  }
  
  return { 
    message: `‚ùó L·ªói: ${rawMessage.substring(0, 100)}`, 
    isRateLimit: false, 
    shouldWait: false 
  };
};

/**
 * NGUY√äN T·∫ÆC V√ÄNG: Chu·∫©n h√≥a vƒÉn b·∫£n ƒë·ªÉ ƒë·ªçc ch√≠nh x√°c 100%
 * Quy t·∫Øc n√†y x·ª≠ l√Ω tri·ªát ƒë·ªÉ l·ªói ƒë·ªçc sai ch√≠nh t·∫£, k√Ω hi·ªáu v√† ƒë·ªãnh d·∫°ng ƒë·∫∑c bi·ªát.
 * 
 * C√°c t√≠nh nƒÉng:
 * 1. Chu·∫©n h√≥a Unicode (NFC): Kh·∫Øc ph·ª•c l·ªói hi·ªÉn th·ªã d·∫•u ti·∫øng Vi·ªát
 * 2. S·ª≠a l·ªói d·∫•u c√¢u: T·ª± ƒë·ªông th√™m kho·∫£ng tr·∫Øng sau d·∫•u c√¢u
 * 3. ƒê·ªçc ƒë√∫ng Ng√†y/Th√°ng: T·ª± ƒë·ªông chuy·ªÉn 10/10/2023 th√†nh ng√†y 10 th√°ng 10 nƒÉm 2023
 * 4. ƒê·ªçc ƒë√∫ng ƒê∆°n v·ªã ƒëo l∆∞·ªùng: T·ª± ƒë·ªông chuy·ªÉn 5kg, 100km, 500ƒë th√†nh ƒë·ªçc ƒë√∫ng
 * 5. M·ªü r·ªông t·ª´ vi·∫øt t·∫Øt: T·ª± ƒë·ªông thay th·∫ø c√°c t·ª´ vi·∫øt t·∫Øt ph·ªï bi·∫øn
 * 6. X·ª≠ l√Ω k√Ω t·ª± ƒë·∫∑c bi·ªát: Chuy·ªÉn g·∫°ch ƒë·∫ßu d√≤ng th√†nh d·∫•u ph·∫©y
 */
export const normalizeTextForSpeech = (text: string): string => {
  if (!text) return "";

  // 1. Chu·∫©n h√≥a Unicode (NFC) ƒë·ªÉ x·ª≠ l√Ω l·ªói font v√† d·∫•u ti·∫øng Vi·ªát
  // V√≠ d·ª•: √≤a vs o√† -> chu·∫©n h√≥a v·ªÅ m·ªôt d·∫°ng
  let processed = text.normalize("NFC");
  processed = processed.replace(/[\u200B-\u200D\uFEFF]/g, " ");

  // 2. X·ª≠ l√Ω ng√†y th√°ng chuy√™n s√¢u (PH·∫¢I X·ª¨ L√ù TR∆Ø·ªöC c√°c k√Ω hi·ªáu to√°n h·ªçc)
  // dd/mm/yyyy -> ng√†y dd th√°ng mm nƒÉm yyyy
  processed = processed.replace(/\b(\d{1,2})\/(\d{1,2})\/(\d{4})\b/g, "ng√†y $1 th√°ng $2 nƒÉm $3");
  // dd/mm -> ng√†y dd th√°ng mm
  processed = processed.replace(/\b(\d{1,2})\/(\d{1,2})\b(?![\/\d])/g, "ng√†y $1 th√°ng $2");

  // 3. X·ª≠ l√Ω k√Ω hi·ªáu to√°n h·ªçc v√† so s√°nh (Tr√°nh ƒë·ªçc sai k√Ω hi·ªáu)
  // FIX: S·ª≠ d·ª•ng lookahead thay v√¨ \b v√¨ % kh√¥ng ph·∫£i word character
  processed = processed.replace(/(\d+)\s*%(?=\s|$|[^\w%])/g, "$1 ph·∫ßn trƒÉm");
  
  // FIX: S·ª≠ d·ª•ng pattern ƒë∆°n gi·∫£n h∆°n, kh√¥ng d√πng lookbehind ƒë·ªÉ t∆∞∆°ng th√≠ch t·ªët h∆°n
  // X·ª≠ l√Ω d·∫•u + khi c√≥ s·ªë ·ªü c·∫£ hai b√™n ho·∫∑c c√≥ kho·∫£ng tr·∫Øng
  processed = processed.replace(/(\d+)\s*\+\s*(\d+)/g, "$1 c·ªông $2");
  processed = processed.replace(/\s\+\s/g, " c·ªông ");
  processed = processed.replace(/\s*=\s*/g, " b·∫±ng ");
  // FIX: S·ª≠a regex > v√† < ƒë·ªÉ kh√¥ng match v·ªõi ƒë∆°n v·ªã ƒëo l∆∞·ªùng (v√≠ d·ª•: 5l kh√¥ng b·ªã match)
  processed = processed.replace(/(\d+)\s*>\s*(\d+)/g, "$1 l·ªõn h∆°n $2");
  processed = processed.replace(/\s*>\s*/g, " l·ªõn h∆°n ");
  processed = processed.replace(/(\d+)\s*<\s*(\d+)/g, "$1 nh·ªè h∆°n $2");
  processed = processed.replace(/\s*<\s*/g, " nh·ªè h∆°n ");
  processed = processed.replace(/(\d+)\s*\*\s*(\d+)/g, "$1 nh√¢n $2");
  // Ch·ªâ x·ª≠ l√Ω ph√©p chia khi kh√¥ng ph·∫£i ng√†y th√°ng (ƒë√£ x·ª≠ l√Ω ·ªü tr√™n)
  processed = processed.replace(/(\d+)\s*\/\s*(\d+)(?!\/)/g, "$1 chia $2");

  // 4. X·ª≠ l√Ω ƒë∆°n v·ªã ti·ªÅn t·ªá v√† ƒëo l∆∞·ªùng (Ch·ªâ khi ƒë·ª©ng sau s·ªë)
  // FIX: S·ª≠ d·ª•ng \d+ thay v√¨ \d ƒë·ªÉ match nhi·ªÅu ch·ªØ s·ªë (5kg, 100km, 500ƒë)
  const units: Record<string, string> = {
    "kg": "ki l√¥ gam", "km": "ki l√¥ m√©t", "cm": "xƒÉng ti m√©t", "mm": "mi li m√©t",
    "m2": "m√©t vu√¥ng", "m3": "m√©t kh·ªëi", "ml": "mi li l√≠t", "l": "l√≠t", "g": "gam",
    "ƒë": "ƒë·ªìng", "vnd": "vi·ªát nam ƒë·ªìng", "usd": "ƒë√¥ la m·ªπ", "tr": "tri·ªáu", "t·ª∑": "t·ª∑"
  };
  
  // S·∫Øp x·∫øp units theo ƒë·ªô d√†i gi·∫£m d·∫ßn ƒë·ªÉ match ƒë∆°n v·ªã d√†i tr∆∞·ªõc (v√≠ d·ª•: "m2" tr∆∞·ªõc "m")
  const sortedUnits = Object.entries(units).sort((a, b) => b[0].length - a[0].length);
  for (const [unit, reading] of sortedUnits) {
    // Escape c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát trong unit
    const escapedUnit = unit.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
    // FIX: S·ª≠ d·ª•ng \d+ v√† lookahead ch·∫∑t ch·∫Ω h∆°n ƒë·ªÉ ƒë·∫£m b·∫£o unit kh√¥ng n·∫±m trong t·ª´ kh√°c
    // Ch·ªâ match khi unit l√† m·ªôt t·ª´ ƒë·ªôc l·∫≠p (c√≥ kho·∫£ng tr·∫Øng ho·∫∑c k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ sau unit)
    // V√† ƒë·∫£m b·∫£o kh√¥ng match khi unit l√† ph·∫ßn c·ªßa t·ª´ kh√°c (v√≠ d·ª•: "l" trong "l·ªõn")
    const regex = new RegExp(`(\\d+)\\s*${escapedUnit}(?=\\s|$|[^\\w\\u00C0-\\u1EF9])`, 'gi');
    processed = processed.replace(regex, `$1 ${reading}`);
  }

  // 5. M·ªü r·ªông t·ª´ vi·∫øt t·∫Øt (Theo danh s√°ch chu·∫©n t·ª´ constants)
  const sortedAbbrs = Object.keys(VIETNAMESE_ABBREVIATIONS).sort((a, b) => b.length - a.length);
  for (const abbr of sortedAbbrs) {
      const fullText = VIETNAMESE_ABBREVIATIONS[abbr];
      const escapedAbbr = abbr.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
      // N·∫øu c√≥ d·∫•u ch·∫•m ·ªü cu·ªëi (TP.), match nguy√™n vƒÉn, n·∫øu kh√¥ng d√πng word boundary
      const regex = abbr.endsWith('.') ? new RegExp(escapedAbbr, 'gi') : new RegExp(`\\b${escapedAbbr}\\b`, 'g');
      processed = processed.replace(regex, fullText + " ");
  }

  // 6. Chu·∫©n h√≥a d·∫•u c√¢u ƒë·ªÉ AI ng·∫Øt ngh·ªâ ƒë√∫ng (D·∫•u c√¢u d√≠nh li·ªÅn)
  // T·ª± ƒë·ªông th√™m kho·∫£ng tr·∫Øng sau d·∫•u c√¢u n·∫øu thi·∫øu
  processed = processed.replace(/([,.!:;?])(?=[^\s\d])/g, '$1 '); // "ch√†o,b·∫°n" -> "ch√†o, b·∫°n"
  // X√≥a kho·∫£ng tr·∫Øng th·ª´a tr∆∞·ªõc d·∫•u c√¢u
  processed = processed.replace(/\s+([,.!:;?])/g, '$1'); // "ch√†o , b·∫°n" -> "ch√†o, b·∫°n"
  
  // 7. X·ª≠ l√Ω g·∫°ch ƒë·∫ßu d√≤ng v√† ph√¢n ƒëo·∫°n (Tr√°nh ƒë·ªçc l√† "tr·ª´")
  // Chuy·ªÉn g·∫°ch ƒë·∫ßu d√≤ng th√†nh d·∫•u ph·∫©y ƒë·ªÉ ng·∫Øt nh·ªãp th·ªü t·ª± nhi√™n h∆°n
  processed = processed.replace(/(^|\n)\s*-\s+/g, "$1, "); 

  // 8. D·ªçn d·∫πp kho·∫£ng tr·∫Øng th·ª´a
  return processed.replace(/\s+/g, ' ').trim();
};

export const generateContentFromDescription = async (prompt: string, modePrompt: string, onLog?: any, apiKey: string = "") => {
  try {
    const ai = new GoogleGenAI({ apiKey });
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: `${modePrompt}\n\n${prompt}\n\nY√™u c·∫ßu: Vi·∫øt ti·∫øng Vi·ªát chu·∫©n, tuy·ªát ƒë·ªëi kh√¥ng vi·∫øt t·∫Øt, kh√¥ng d√πng ti·∫øng l√≥ng.`,
    });
    return response.text || '';
  } catch (error: any) { throw new Error(handleAiError(error).message); }
};

export const generateAudioSegment = async (
  text: string, 
  config: any, 
  onLog?: any, 
  apiKey: string = "",
  retryCount: number = 0,
  maxRetries: number = 3
): Promise<ArrayBuffer> => {
  try {
    const ai = new GoogleGenAI({ apiKey });
    const response = await withTimeout(
      ai.models.generateContent({
        model: "gemini-2.5-flash-preview-tts",
        contents: [{ parts: [{ text }] }],
        config: {
          responseModalities: [Modality.AUDIO],
          speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: config.voiceName } } },
        },
      }),
      30000 // 30 seconds timeout
    );
    const base64 = response.candidates?.[0]?.content?.parts?.find(p => p.inlineData)?.inlineData?.data;
    if (!base64) throw new Error("TTS Failure");
    const binary = atob(base64);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
    return bytes.buffer;
  } catch (error: any) {
    const errorInfo = handleAiError(error);
    
    // Retry logic v·ªõi exponential backoff
    if (retryCount < maxRetries && (errorInfo.isRateLimit || errorInfo.shouldWait)) {
      const waitTime = errorInfo.retryAfter || (1000 * Math.pow(2, retryCount));
      if (onLog) onLog(`Segment error, retrying (${retryCount + 1}/${maxRetries}) after ${Math.round(waitTime/1000)}s...`, 'warning');
      await delay(waitTime);
      return generateAudioSegment(text, config, onLog, apiKey, retryCount + 1, maxRetries);
    }
    
    throw new Error(errorInfo.message);
  }
};

export const generateAudioParallel = async (text: string, config: any, onProgress: any, onLog?: any, apiKey: string = ""): Promise<ArrayBuffer> => {
  // B∆Ø·ªöC QUAN TR·ªåNG: Chu·∫©n h√≥a vƒÉn b·∫£n tr∆∞·ªõc khi chia nh·ªè
  const normalizedText = normalizeTextForSpeech(text);
  
  const rawChunks = normalizedText.match(/[^.!?\n]+[.!?\n]*|[^.!?\n]+/g) || [normalizedText];
  const combinedChunks: string[] = [];
  let current = "";
  const LIMIT = 600; 

  for (const c of rawChunks) {
    if ((current + c).length < LIMIT) current += c;
    else { if (current) combinedChunks.push(current.trim()); current = c; }
  }
  if (current) combinedChunks.push(current.trim());

  // Adaptive delay: tƒÉng delay n·∫øu g·∫∑p rate limit
  let adaptiveDelay = 1200; // Base delay
  const results: ArrayBuffer[] = [];
  
  for (let i = 0; i < combinedChunks.length; i++) {
    if (i > 0) {
      await delay(adaptiveDelay); // S·ª≠ d·ª•ng adaptive delay
      if (onLog) onLog(`Processing segment ${i + 1}/${combinedChunks.length}...`, 'info');
    }
    
    try {
      const segment = await generateAudioSegment(combinedChunks[i], config, onLog, apiKey);
      results.push(segment);
      
      // Gi·∫£m delay n·∫øu response nhanh (th√†nh c√¥ng)
      adaptiveDelay = Math.max(adaptiveDelay * 0.95, 800); // Min 800ms
      
      onProgress(Math.round(((i + 1) / combinedChunks.length) * 100));
    } catch (error: any) {
      // TƒÉng delay n·∫øu g·∫∑p l·ªói rate limit
      const errorInfo = handleAiError(error);
      if (errorInfo.isRateLimit || errorInfo.shouldWait) {
        adaptiveDelay = Math.min(adaptiveDelay * 1.5, 5000); // Max 5 seconds
        if (onLog) onLog(`Rate limit detected, increasing delay to ${Math.round(adaptiveDelay)}ms`, 'warning');
      }
      throw error; // Re-throw ƒë·ªÉ caller x·ª≠ l√Ω retry v·ªõi key rotation
    }
  }

  const totalLength = results.reduce((acc, b) => acc + b.byteLength, 0);
  const finalBuffer = new Uint8Array(totalLength);
  let offset = 0;
  for (const res of results) {
    finalBuffer.set(new Uint8Array(res), offset);
    offset += res.byteLength;
  }
  return finalBuffer.buffer;
};

export const pcmToWav = (pcmBuffer: ArrayBuffer, sampleRate: number = 24000): Blob => {
  const length = pcmBuffer.byteLength;
  const buffer = new ArrayBuffer(44 + length);
  const view = new DataView(buffer);
  view.setUint32(0, 0x52494646, false); 
  view.setUint32(4, 36 + length, true); 
  view.setUint32(8, 0x57415645, false);
  view.setUint32(12, 0x666d7420, false); 
  view.setUint32(16, 16, true); 
  view.setUint16(20, 1, true);
  view.setUint16(22, 1, true); 
  view.setUint32(24, sampleRate, true); 
  view.setUint32(28, sampleRate * 2, true);
  view.setUint16(32, 2, true); 
  view.setUint16(34, 16, true); 
  view.setUint32(36, 0x64617461, false);
  view.setUint32(40, length, true); 
  new Uint8Array(buffer, 44).set(new Uint8Array(pcmBuffer));
  return new Blob([buffer], { type: 'audio/wav' });
};

export const pcmToMp3 = (pcmBuffer: ArrayBuffer, sampleRate: number = 24000): Blob => {
  const lamejs = (window as any).lamejs;
  if (!lamejs?.Mp3Encoder) return pcmToWav(pcmBuffer, sampleRate);
  const encoder = new lamejs.Mp3Encoder(1, sampleRate, 128);
  const samples = new Int16Array(pcmBuffer);
  const mp3Data = [];
  for (let i = 0; i < samples.length; i += 1152) {
    const chunk = samples.subarray(i, i + 1152);
    const mp3buf = encoder.encodeBuffer(chunk);
    if (mp3buf.length > 0) mp3Data.push(mp3buf);
  }
  const final = encoder.flush();
  if (final.length > 0) mp3Data.push(final);
  return new Blob(mp3Data, { type: 'audio/mp3' });
};

export const analyzeVoice = async (rawAudioBuffer: ArrayBuffer, onLog?: (m: string, t: 'info' | 'error') => void, apiKey: string = ""): Promise<any> => {
  const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
  const audioBuffer = await audioContext.decodeAudioData(rawAudioBuffer.slice(0));
  const durationToKeep = Math.min(audioBuffer.duration, 20);
  const framesToKeep = Math.floor(durationToKeep * audioBuffer.sampleRate);
  const newBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, framesToKeep, audioBuffer.sampleRate);
  for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
    newBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).slice(0, framesToKeep));
  }
  const wavBlob = pcmToWav(audioBufferToWav(newBuffer), audioBuffer.sampleRate);
  const reader = new FileReader();
  const base64 = await new Promise<string>((resolve) => {
    reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
    reader.readAsDataURL(wavBlob);
  });

  try {
    const ai = new GoogleGenAI({ apiKey });
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview', 
      contents: {
        parts: [
          { inlineData: { data: base64, mimeType: 'audio/wav' } },
          { text: `Analyze this audio. Return JSON: gender ("Nam"/"N·ªØ"), region ("B·∫Øc"/"Trung"/"Nam"), toneSummary (5 words), suggestedName (Vietnamese), description.` }
        ]
      },
      config: { responseMimeType: "application/json" }
    });
    
    let jsonText = response.text || "{}";
    jsonText = jsonText.replace(/^```json\s*/, '').replace(/\s*```$/, '');
    return JSON.parse(jsonText);
  } catch (e: any) {
    throw new Error(handleAiError(e).message);
  }
};

function audioBufferToWav(buffer: AudioBuffer): ArrayBuffer {
  const numChannels = buffer.numberOfChannels;
  const length = buffer.length * numChannels * 2;
  const result = new ArrayBuffer(length);
  const view = new DataView(result);
  const channels = [];
  for (let i = 0; i < numChannels; i++) channels.push(buffer.getChannelData(i));
  let offset = 0;
  for (let i = 0; i < buffer.length; i++) {
    for (let channel = 0; channel < numChannels; channel++) {
      let sample = channels[channel][i];
      sample = Math.max(-1, Math.min(1, sample));
      view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
      offset += 2;
    }
  }
  return result;
}

export const generateMarketingContent = async (imageBase64: string | null, description: string, onLog?: any, apiKey: string = "") => {
  try {
    const ai = new GoogleGenAI({ apiKey });
    const parts: any[] = [];
    if (imageBase64) parts.push({ inlineData: { mimeType: 'image/jpeg', data: imageBase64 } });
    parts.push({ text: `ƒê√≥ng vai chuy√™n gia marketing. D·ª±a tr√™n: "${description}", t·∫°o ti√™u ƒë·ªÅ (d∆∞·ªõi 10 t·ª´) v√† n·ªôi dung qu·∫£ng c√°o (30 t·ª´) h·∫•p d·∫´n. Tr·∫£ v·ªÅ JSON {title, content}.` });
    const response = await ai.models.generateContent({ model: 'gemini-3-flash-preview', contents: { parts }, config: { responseMimeType: "application/json" } });
    
    let jsonText = response.text || "{}";
    jsonText = jsonText.replace(/^```json\s*/, '').replace(/\s*```$/, '');
    return JSON.parse(jsonText);
  } catch (e: any) { throw new Error(handleAiError(e).message); }
};

export const generateAdImage = async (prompt: string, onLog?: any, apiKey: string = "") => {
  try {
    const ai = new GoogleGenAI({ apiKey });
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: [{ text: `High-quality advertising background: ${prompt}. No text.` }],
      config: { imageConfig: { aspectRatio: "1:1" } }
    });
    const part = response.candidates?.[0]?.content?.parts?.find(p => p.inlineData);
    if (!part) throw new Error("AI kh√¥ng tr·∫£ v·ªÅ ·∫£nh.");
    return `data:image/png;base64,${part.inlineData.data}`;
  } catch (e: any) { throw new Error(handleAiError(e).message); }
};
